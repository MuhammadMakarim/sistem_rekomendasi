# -*- coding: utf-8 -*-
"""Submission_akhir_Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ecTNhOcC3BDhIE1xjQBrKvtby1iOIxOq

# **Sistem Rekomendasi Proyek Machine Learning Terapan**
- **Nama:** Muhammad Makarim
- **Email:** mmakarim9@student.ub.ac.id
- **ID Dicoding:** MC006D5Y1427

## **Import Semua Packages/Library yang Digunakan**

Import semua Library yang akan digunakan nantinya
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import kagglehub
import os
import warnings
warnings.filterwarnings("ignore")

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse.linalg import svds
from sklearn.metrics import mean_squared_error
from sklearn.metrics.pairwise import cosine_similarity

"""## **Data Preparation**

### **Data Loading**

Download latest version dataset dari kaggle menggunakan kagglehub
"""

# Download latest version
path = kagglehub.dataset_download("CooperUnion/anime-recommendations-database")

print("Path to dataset files:", path)

data_dir = '/kaggle/input/anime-recommendations-database'

"""Load data dari anime.csv dan rating.csv"""

anime_csv  = os.path.join(data_dir, "anime.csv")
rating_csv = os.path.join(data_dir, "rating.csv")

"""Membaca data.csv yang sudah dibaca dan disimpan pada df_anime dan df_rating"""

df_anime  = pd.read_csv(anime_csv)
df_rating = pd.read_csv(rating_csv)

"""Mengecek shape di kedua Dataframe"""

# Mengecek shape df_anime
print("Shape df_anime:", df_anime.shape)

# Mengecek shape df_rating
print("Shape df_rating:", df_rating.shape)

"""Dikarenakan pada df_rating mempunyai lebih dari 7jt data, maka akan diambil sebesar 1% data dari df_rating"""

df_rating = df_rating.sample(frac=0.01, random_state=42)

"""Mengecek kembali shape df_rating"""

# Mengecek shape df_rating
print("Shape df_rating:", df_rating.shape)

"""insight: df_anime mempunyai shape (12294, 7), dan df_rating mempunyai shape (78137, 3) dimana df_rating hanya sampel 1% dari data awal yang berjumlah 7jt lebih

Menampilkan 5 data paling atas untuk df_anime
"""

display(df_anime.head())

"""Menampilkan 5 data paling atas untuk df_rating"""

display(df_rating.head())

"""## **Data Understanding**

Di bagian ini, kita uraikan asal data, struktur tabel, dan insight awal melalui eksplorasi

### **Jumlah record & contoh data**
"""

print(f"Jumlah record anime : {df_anime.shape[0]:,}")
print(f"Jumlah record rating: {df_rating.shape[0]:,}\n")

print("Contoh 5 baris pertama (anime.csv):")
display(df_anime.head(5))
print("\nContoh 5 baris pertama (rating.csv):")
display(df_rating.head(5))

"""### **Daftar fitur & tipe data**

Daftar fitur dan tipe data dari df_anime dan df_rating
"""

print("\nFitur anime.csv:")
for col, dtype in zip(df_anime.columns, df_anime.dtypes):
    print(f" - {col}: {dtype}")
print("\nFitur rating.csv:")
for col, dtype in zip(df_rating.columns, df_rating.dtypes):
    print(f" - {col}: {dtype}")

"""Insight: profiling awal pada data dengan menampilkan nama dan tipe data dari setiap fitur, memberikan pemahaman dasar tentang apa data yang Anda miliki dan formatnya.

### **Cek missing values**

Identifikasi jumlah nilai yang hilang (missing values) di setiap kolom pada kedua dataframe.
"""

print("\nMissing values (anime.csv):")
print(df_anime.isnull().sum())
print("\nMissing values (rating.csv):")
print(df_rating.isnull().sum())

"""Hasil cek menunjukkan adanya missing values pada kolom-kolom tertentu di df_anime (seperti genre, type, episodes, rating, members) dan df_rating (pada rating). Ini mengindikasikan perlunya penanganan missing values pada tahap preprocessing.

### **Cek Duplikasi Data**

Periksa apakah ada baris data yang terduplikasi secara persis di kedua dataframe.
"""

duplicate_count = df_anime.duplicated().sum()
print(f"Jumlah data duplikat df_anime: {duplicate_count}")
duplicate_count = df_rating.duplicated().sum()
print(f"Jumlah data duplikat df_rating: {duplicate_count}")

"""Hasil cek menunjukkan bahwa data duplikat tidak ditemukan di df_anime dan di df_rating.

### **Statistik deskriptif dasar**

Hitung dan tampilkan statistik deskriptif dasar (count, mean, std, min, max, quartile) untuk kolom-kolom numerik di kedua dataframe.
"""

print("\nDescriptive statistics (anime.csv):")
display(df_anime.describe())
print("\nDescriptive statistics (rating.csv):")
display(df_rating.describe())

"""Insight: Statistik deskriptif memberikan ringkasan distribusi nilai pada kolom numerik seperti rating, members, dan episodes.

### **Insight awal**

Hitung jumlah pengguna unik, jumlah anime unik, dan jumlah rating bernilai 0 (implicit clicks) dalam data rating.
"""

n_users  = df_rating['user_id'].nunique()
n_anime  = df_rating['anime_id'].nunique()
zero_click = (df_rating['rating'] == 0).sum()
print(f"\nJumlah user unik      : {n_users:,}")
print(f"Jumlah anime unik     : {n_anime:,}")
print(f"Jumlah implicit clicks (rating=0): {zero_click:,}")

"""Terdapat 33,919 pengguna unik dan 5,408 anime yang terlibat dalam interaksi rating.

## **Exploratory Data Analysis**

### **Distribusi Rating Pengguna**

Visualisasikan sebaran frekuensi setiap nilai rating dari 0 hingga 10.
"""

plt.figure(figsize=(8,4))
sns.countplot(data=df_rating, x='rating', color='steelblue')
plt.title('Distribusi seluruh nilai rating (0–10)')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.xticks(range(0,11))
plt.tight_layout()
plt.show()

"""Insight: Plot menunjukkan bahwa nilai rating 0 memiliki frekuensi yang jauh lebih tinggi dibandingkan rating eksplisit (1-10), menegaskan adanya banyak implicit clicks. Distribusi rating eksplisit mungkin menunjukkan preferensi pengguna terhadap nilai rating tertentu (misalnya, rating tinggi lebih umum).

### **Rating Korelasi**

Hitung dan visualisasikan matriks korelasi antar fitur numerik pada df_anime
"""

# Korelasi numerik: episodes, members, score
num_df = df_anime[['episodes','members','rating']].copy()

# Ubah episodes ke numerik, drop invalid
num_df['episodes'] = pd.to_numeric(num_df['episodes'], errors='coerce')
num_df = num_df.replace(0, pd.NA).dropna()

plt.figure(figsize=(6,5))
sns.heatmap(num_df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix (anime numeric features)')
plt.tight_layout()
plt.show()

"""Bagian ini memilih kolom episodes, members, dan rating dari df_anime. Kolom episodes diubah menjadi tipe numerik. Nilai 0 dan missing values dihapus karena tidak relevan untuk analisis korelasi numerik. Kemudian, dihitung matriks korelasi antar kolom-kolom numerik tersebut.

Insight: Hasil dari heatmap ini akan menunjukkan seberapa kuat hubungan linier antara jumlah episode, jumlah anggota komunitas (members), dan rata-rata rating sebuah anime. Misalnya, jika ada korelasi positif yang kuat antara members dan rating, itu bisa berarti anime yang punya banyak anggota komunitas cenderung memiliki rating yang lebih tinggi.

### **Top-N Anime berdasarkan Jumlah Rating & Rata-Rata Rating**

**rating >0**
"""

agg = df_rating[df_rating.rating>0] \
      .groupby('anime_id')['rating'] \
      .agg(['count','mean']) \
      .reset_index() \
      .merge(df_anime[['anime_id','name']], on='anime_id')

"""*   Insight: Memfilter rating yang bernilai > 0 (mengabaikan implicit clicks). Kemudian, data rating dikelompokkan berdasarkan anime_id. Untuk setiap anime_id, dihitung jumlah rating (count) dan rata-rata rating (mean). Hasilnya kemudian digabungkan dengan DataFrame df_anime untuk mendapatkan nama anime. Hasilnya disimpan dalam DataFrame agg.

**Top 10 by count**
"""

top_count = agg.nlargest(10, 'count')
plt.figure(figsize=(8,5))
sns.barplot(data=top_count, x='count', y='name', palette='viridis')
plt.title('Top 10 Anime by Number of Ratings')
plt.xlabel('Number of Ratings')
plt.ylabel('Anime')
plt.tight_layout()
plt.show()

"""Insight: Dari analisis yang dilakukan, terlihat bahwa anime "Death Note" memiliki jumlah rating tertinggi, diikuti oleh "Sword Art Online" dan "Elfen Lied".

**Top N by average rating (with min count threshold)**

Visualisasi top anime by average rating
"""

min_count = 250
top_mean = agg[agg['count']>=min_count].nlargest(10, 'mean')
plt.figure(figsize=(8,5))
sns.barplot(data=top_mean, x='mean', y='name', palette='magma')
plt.title(f'Top Anime by Average Rating (count ≥ {min_count})')
plt.xlabel('Average Rating')
plt.ylabel('Anime')
plt.tight_layout()
plt.show()

"""Insight: Dari hasil yang didapat melalui visualisasi, anime "Death Note" menduduki peringkat tertinggi dalam rating rata-rata, diikuti oleh "Elfen Lied" dan "Sword Art Online", dengan kriteria minimal 250 rating.

### **Genre Explosion & Top Genres**

**All Genre**

Analisis semua genre yang ada di df_anime
"""

genre_set = set()
for genre_string in df_anime['genre'].dropna():
    genres = genre_string.split('|')
    genre_set.update(genres)

print("Total of unique genre:", len(genre_set))
print("list of unique genre:")
for genre in sorted(genre_set):
    print("-", genre)

"""insight: Terdapat total 3,128 genre unik di dalam dataset, menunjukkan keragaman genre dan tema yang ada pada Dataframe anime.

**Top 20 Genre**

Visualisasi top 20 Genre dari anime yang ada pada Dataframe
"""

genre_exploded = df_anime['genre'].dropna().str.split('|').explode()
top_genres = genre_exploded.value_counts().head(20)
plt.figure(figsize=(8,5))
sns.barplot(x=top_genres.values, y=top_genres.index, palette='cubehelix')
plt.title('Top 20 Genres')
plt.xlabel('Count of Anime')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""Insight: Genre "Comedy" mendominasi daftar dengan jumlah anime terbanyak, diikuti oleh "Music" dan "Kids". Ini menunjukkan bahwa genre "Comedy" menjadi tema yang paling banyak dan populer.

### **Tipe Anime**

Visualisasi tipe dari Anime yang ada pada Dataframe
"""

plt.figure(figsize=(6,4))
sns.countplot(data=df_anime, y='type',
              order=df_anime['type'].value_counts().index,
              palette='pastel')
plt.title('Distribusi Tipe Anime')
plt.xlabel('Count')
plt.ylabel('Type')
plt.tight_layout()
plt.show()

"""Insight: Dalam distribusi tipe anime, kategori "TV" mendominasi dengan jumlah terbanyak, mencapai hampir 3,500 judul. Ini menunjukkan bahwa format serial TV lebih populer dan lebih banyak diproduksi dibandingkan dengan tipe lainnya seperti "Movie", "OVA", dan "Special". Tipe "Movie" berada di urutan kedua dengan jumlah yang signifikan, diikuti oleh "OVA" (Original Video Animation) dan "Special". Tipe "ONA" (Original Net Animation) memiliki jumlah yang lebih sedikit, dan "Music" adalah kategori dengan jumlah terendah.

## **Data Preprocessing**

### **Cleaning Data dari Missing Value**

**Melakukan Penanganan Missing Values pada Data Anime**
"""

df_anime['genre']    = df_anime['genre'].fillna('')
df_anime['type']     = df_anime['type'].fillna('Unknown')
df_anime['episodes'] = (pd.to_numeric(df_anime['episodes'], errors='coerce')
                         .fillna(0).astype(int))
df_anime['members']  = df_anime['members'].fillna(0).astype(int)

mean_score = df_anime['rating'].mean()
df_anime['rating']    = df_anime['rating'].fillna(mean_score)

"""**Melakukan Penanganan Missing Values pada Data Rating**"""

# Cleaning rating data
df_rating['rating'] = pd.to_numeric(df_rating['rating'], errors='coerce')
df_rating = df_rating.dropna(subset=['rating'])

# Split explicit vs implicit
df_rating_cf  = df_rating[df_rating.rating > 0].copy()
df_rating_imp = df_rating[df_rating.rating == 0].copy()

# Filter batas minimum interaksi
min_per_user  = 20
min_per_anime = 20

active_u = df_rating_cf['user_id'].value_counts()
active_a = df_rating_cf['anime_id'].value_counts()

keep_users = active_u[active_u >= min_per_user].index
keep_anime  = active_a[active_a >= min_per_anime].index

df_rating_cf = df_rating_cf[
    df_rating_cf.user_id.isin(keep_users) &
    df_rating_cf.anime_id.isin(keep_anime)
].reset_index(drop=True)

"""**Cek Missing Values kembali setelah di tangani**"""

print("\nMissing values (anime.csv):")
print(df_anime.isnull().sum())
print("\nMissing values (rating.csv):")
print(df_rating.isnull().sum())

"""Insight: Missing values sudah berhasil di tangani di kedua Dataframe

### **Feature Engineering (Content-Based)**

Inisialisasi TF-IDF untuk kolom genre dan maping anime_id
"""

tfidf = TfidfVectorizer(token_pattern=r"(?u)\b\w+\b")
tfidf_matrix = tfidf.fit_transform(df_anime['genre'])

anime_idx_map = pd.Series(df_anime.index, index=df_anime['anime_id'])

"""### **Feature Engineering (Collaborative Filtering)**

Melakukan Feature Engineering sebelum melakukan model development menggunakan pendekatan Collaborative Filtering
"""

user_matrix_train = df_rating.pivot_table(index='user_id', columns='anime_id', values='rating').fillna(0) # <-- Updated

user_ids = user_matrix_train.index.tolist()
item_ids = user_matrix_train.columns.tolist()

"""Insight: Proses ini bertujuan untuk membangun matriks interaksi pengguna dan anime dengan mengisi nilai hilang untuk mempersiapkan data yang diperlukan dalam sistem rekomendasi berbasis kolaboratif.

## **Model Development dengan Content Based Filtering**

Dalam pendekatan content-based filtering, kita memanfaatkan fitur tiap anime (genre, type, episodes, members, score) untuk membangun rekomendasi berdasarkan kemiripan konten.

### **Representasi Fitur**

**TF-IDF matrix untuk genre**
"""

tfidf_matrix = tfidf.fit_transform(df_anime['genre'])

"""**Scaling fitur numerik: rating & members**


"""

scaler = MinMaxScaler()
num_features = scaler.fit_transform(df_anime[['rating', 'members']])

"""**Gabungkan vektor teks & numerik**"""

from scipy.sparse import hstack
feature_matrix = hstack([tfidf_matrix, np.array(num_features)])

"""### **Hitung Similarity**"""

cosine_sim = cosine_similarity(feature_matrix, feature_matrix)

"""### **Fungsi Rekomendasi**

**Membuat Fungsi dan Visualisasi Fungsi Rekomendasi**
"""

def recommend_content_verbose(anime_id, top_n=5):
    # Cari index target
    idx = anime_idx_map[anime_id]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Pilih top_n teratas (kecuali sendiri)
    top = sim_scores[1 : top_n+1]
    rec_indices = [i for i, _ in top]
    rec_sims    = [s for _, s in top]

    # Tampilkan detail target anime
    target = df_anime[df_anime['anime_id']==anime_id].iloc[0]
    print(f"=== Target Anime (ID={anime_id}) ===")
    display(target[['name','genre','type','episodes','members','rating']])

    # Kumpulkan detail rekomendasi
    recs = df_anime.iloc[rec_indices].copy()
    recs['similarity'] = rec_sims
    recs = recs[['anime_id','name','genre','type','episodes','members','rating','similarity']]

    print(f"\n=== Top {top_n} Recommendations ===")
    display(recs.reset_index(drop=True))

    # Visualisasi similarity
    plt.figure(figsize=(10,4))
    sns.barplot(data=recs, x='similarity', y='name', palette='viridis')
    plt.title(f'Similarity to "{target["name"]}"')
    plt.xticks(rotation=45, ha='right')
    plt.ylabel('Cosine Similarity')
    plt.xlabel('Recommended Anime')
    plt.tight_layout()
    plt.show()

    return recs

"""**Mencoba Fungsi Rekomendasi**

Percobaan 1
"""

recs_for_1 = recommend_content_verbose(anime_id=1, top_n=10)

"""Insight: Dari hasil rekomendasi menunjukkan bahwa anime "Cowboy Bebop" memiliki banyak kesamaan dengan judul lain, terutama dalam genre aksi, petualangan, dan drama. Rekomendasi teratas termasuk judul-judul seperti "Cowboy Bebop: Yosai Atsume Blues" dan "Waga Seishun no Arcadia," yang memiliki rating dan episode cukup baik. Selain itu, tingkat kesamaan antara anime yang direkomendasikan bervariasi, memberikan pengguna banyak pilihan untuk menjelajahi anime yang sesuai dengan preferensi mereka berdasarkan elemen yang serupa dengan "Cowboy Bebop."

Percobaan 2 (menggunakan random untuk anime_id)
"""

import random

random.seed(42)
all_ids = df_anime['anime_id'].tolist()
rand_id = random.choice(all_ids)

recs_for_random = recommend_content_verbose(anime_id=rand_id, top_n=10)

"""Insight: Dari hasil rekomendasi untuk anime "Tamagotchi! Miracle Friends" menunjukkan bahwa semua rekomendasi teratas berputar di sekitar genre komedi, fantasi, dan anak-anak, dengan anime seperti "GO-GO Tamagotchi!" dan "Doraemon: Doraemon Comes Back" yang memiliki kesamaan tinggi. Tingkat kesamaan yang sangat tinggi (mendekati 1) antara anime yang direkomendasikan menunjukkan bahwa karakteristik konten, termasuk tema dan gaya, sangat mirip, memberikan opsi yang relevan bagi pengguna yang mencari tontonan serupa. Dengan berbagai pilihan tersedia, pengguna dapat dengan mudah menemukan anime yang sesuai dengan preferensi mereka dalam genre ini.

### **Kelebihan & Kekurangan Model Development dengan Content Based Filtering**

Model rekomendasi berbasis konten *Content-Based Filtering* bekerja dengan merekomendasikan item kepada pengguna berdasarkan kemiripan atribut atau fitur dari item yang disukai pengguna di masa lalu. Berikut adalah kelebihan dan kekurangannya:

**Kelebihan Content-Based Filtering**
1. Tidak Membutuhkan Data Pengguna Lain *Independence from other users*:

  Model ini hanya memerlukan data historis preferensi satu pengguna (item apa yang disukai, rating yang diberikan) dan fitur-fitur dari item itu sendiri. Ini sangat menguntungkan untuk pengguna baru atau item baru (cold-start problem) karena model tetap bisa memberikan rekomendasi asalkan ada sedikit informasi preferensi dari pengguna tersebut atau fitur dari item tersebut.
2. Kemampuan Merekomendasikan Item Baru *Novelty*:

  Content-based filtering dapat merekomendasikan item yang belum pernah dilihat atau diberi rating oleh pengguna lain, selama item tersebut memiliki fitur yang mirip dengan item yang disukai pengguna. Ini berbeda dengan Collaborative Filtering yang cenderung merekomendasikan item yang sudah populer atau sering berinteraksi.
3. Sangat Berguna untuk Item dengan Fitur Kaya *Rich Features*:

  Model ini bekerja sangat baik ketika item memiliki deskripsi atau atribut yang detail (misalnya, genre film, deskripsi produk, kata kunci artikel). Semakin kaya fitur item, semakin akurat kemiripan antar item dapat dihitung.


**Kekurangan Content-Based Filtering**
1. Over-specialization *Filter Bubble*:

  Model ini cenderung merekomendasikan item yang sangat mirip dengan item yang sudah disukai pengguna. Hal ini bisa membatasi pengguna dalam menemukan item baru yang berada di luar selera mereka saat ini, menciptakan "gelembung filter" di mana pengguna terus-menerus terpapar pada jenis konten yang sama.
2. Keterbatasan pada Fitur Item *Limited Content Analysis*:

  Kualitas rekomendasi sangat bergantung pada seberapa baik fitur-fitur item merepresentasikan konten atau daya tarik item tersebut. Jika fitur yang tersedia kurang informatif atau tidak menangkap semua aspek relevan dari item, rekomendasi bisa menjadi kurang akurat atau tidak menarik.
3. Tidak Mempertimbangkan Popularitas atau Kualitas Universal *Ignores Popularity/Quality*:

  Jika fitur item berupa teks (seperti deskripsi, review), model memerlukan teknik pemrosesan bahasa alami (NLP) seperti TF-IDF atau embedding untuk mengubah teks menjadi representasi numerik yang dapat dibandingkan. Ini bisa menambah kompleksitas pada proses pengembangan.


Secara keseluruhan, Content-Based Filtering adalah pendekatan yang kuat, terutama untuk mengatasi masalah cold-start pengguna dan memberikan penjelasan yang jelas. Namun, untuk memberikan rekomendasi yang lebih beragam dan akurat secara sosial, seringkali model ini dikombinasikan dengan pendekatan lain seperti Collaborative Filtering.

### **Evaluasi Menggunakan RMSE**

Bagian untuk mengevaluasi performa model rekomendasi berbasis konten (Content-Based Filtering) yang telah dikembangkan sebelumnya. Metrik evaluasi yang digunakan adalah Root Mean Squared Error (RMSE).
"""

def evaluate_content_based(recommendations_df):
  if recommendations_df.empty:
    print("No recommendations to evaluate.")
    return np.nan

  # Calculate the average rating of the recommended items
  avg_recommended_rating = recommendations_df['rating'].mean()

  # Calculate the mean squared error of recommended anime ratings from their mean
  mse = mean_squared_error([avg_recommended_rating] * len(recommendations_df), recommendations_df['rating'])

  rmse = np.sqrt(mse)

  print(f"RMSE (Avg. rating of recommended items compared to their mean): {rmse:.4f}")

  return rmse

"""Fungsi ini menerima satu parameter, yaitu recommendations_df. Parameter ini diharapkan adalah DataFrame Pandas yang berisi daftar anime yang direkomendasikan, dan yang terpenting, memiliki kolom rating yang menyimpan nilai rating sebenarnya dari anime tersebut. DataFrame ini kemungkinan besar adalah hasil dari pemanggilan fungsi rekomendasi sebelumnya, seperti recommend_content_verbose.

Tujuan bagian ini untuk menghitung nilai RMSE dari sekumpulan anime yang direkomendasikan. Perlu diperhatikan bahwa cara penghitungan RMSE di sini sedikit spesifik: ia mengukur seberapa jauh rating sebenarnya dari setiap anime yang direkomendasikan menyimpang dari rata-rata rating dari keseluruhan anime yang direkomendasikan dalam set tersebut. Ini bukan evaluasi prediksi rating pengguna, melainkan evaluasi dispersi rating di antara item yang direkomendasikan.


"""

print("\n--- Evaluation for Recommendation Set 1 ---")
rmse_set1 = evaluate_content_based(recs_for_1)

print("\n--- Evaluation for Recommendation Set 2 (Random) ---")
rmse_set2 = evaluate_content_based(recs_for_random)

"""Bagian ini menjalankan fungsi evaluate_content_based untuk dua set rekomendasi yang dihasilkan pada langkah Model Development Content-Based sebelumnya. Meskipun kode ini tidak secara eksplisit mencetak nilai rmse_set1 atau rmse_set2 setelah disimpan, pemanggilan fungsi evaluate_content_based di dalam fungsi itu sendiri sudah mencetak hasilnya ke layar."""

print("\n--- Evaluation for Recommendation Set 1 ---")
rmse_set1 = evaluate_content_based(recs_for_1)

print("\n--- Evaluation for Recommendation Set 2 (Random) ---")
rmse_set2 = evaluate_content_based(recs_for_random)

"""1. Evaluation for Recommendation Set 1:
  menunjukkan nilai RMSE sebesar 0.2728. Angka ini berarti bahwa, rata-rata, rating aktual dari 10 anime yang direkomendasikan karena dianggap mirip dengan anime ID 1 memiliki perbedaan sekitar 0.2728 poin dari rata-rata rating keseluruhan 10 anime tersebut. Nilai RMSE ini mengindikasikan tingkat variasi rating di dalam set rekomendasi pertama.
2. Evaluation for Recommendation Set 2 (Random):
  Output evaluasi kedua, menunjukkan nilai RMSE sebesar 0.2138. Angka ini berarti bahwa, rata-rata, rating aktual dari 10 anime yang direkomendasikan karena dianggap mirip dengan anime dengan ID acak memiliki perbedaan sekitar 0.2138 poin dari rata-rata rating keseluruhan 10 anime tersebut. Nilai RMSE ini mengindikasikan tingkat variasi rating di dalam set rekomendasi kedua

Dengan membandingkan kedua nilai RMSE, kita melihat bahwa nilai pada Set 2 (0.2138) lebih rendah dari Set 1 (0.2728). Ini menyiratkan bahwa set anime yang direkomendasikan pada Set 2 memiliki rating aktual yang secara internal lebih konsisten atau kurang bervariasi dibandingkan dengan set anime yang direkomendasikan pada Set 1.

## **Model Development dengan Collaborative Filtering**

### **Definisi & Pelatihan Model**

**Model-Based CF: SVD**
"""

from scipy.sparse.linalg import svds
import numpy as np
import pandas as pd

# 1) Decompose dengan k faktor laten
U, sigma_vals, Vt = svds(user_matrix_train.values, k=50)
sigma = np.diag(sigma_vals)

# 2) Rekonstruksi prediksi rating
all_user_pred = np.dot(np.dot(U, sigma), Vt)
pred_df_svd = pd.DataFrame(
    all_user_pred,
    index=user_ids,
    columns=item_ids
)

"""### **Fungsi Top-N Recommendation**"""

def get_top_n(pred_df, user_id, n=5):
    # ambil prediksi untuk user_id
    user_preds = pred_df.loc[user_id]
    # ambil item yang belum dirating asli
    already_rated = user_matrix_train.loc[user_id] > 0
    # filter dan urutkan
    recommendations = (
        user_preds[~already_rated]
        .sort_values(ascending=False)
        .head(n)
    )
    return recommendations.index.tolist(), recommendations.values.tolist()

"""### **Tampilkan Rekomendasi**"""

from IPython.display import display

def recommend_cf_verbose(user_id, pred_df, df_anime, user_matrix, top_n=5):
    print(f"=== Rekomendasi untuk user_id={user_id} ===")
    # Get items the user has already rated from the training matrix
    already_rated_ids = user_matrix.loc[user_id][user_matrix.loc[user_id] > 0].index.tolist()

    # Display anime the user has already rated (optional, for context)
    if already_rated_ids:
        print("\n--- Anime yang sudah dirating oleh user ---")
        rated_anime = df_anime[df_anime['anime_id'].isin(already_rated_ids)][['anime_id', 'name', 'genre', 'type', 'rating']]
        display(rated_anime.reset_index(drop=True))
    else:
        print("\n--- User belum merating anime apapun di data training ---")

    # Get the top N recommended anime IDs and predicted scores
    rec_ids, rec_scores = get_top_n(pred_df, user_id, n=top_n)

    # Get details of recommended anime
    recs_df = pd.DataFrame({
        'anime_id': rec_ids,
        'predicted_rating': rec_scores
    }).merge(
        df_anime[['anime_id', 'name', 'genre', 'type', 'rating']],
        on='anime_id'
    )

    print(f"\n--- Top {top_n} Rekomendasi CF ---")
    # --- MODIFIKASI BAGIAN INI ---
    # Menggunakan opsi tampilan sementara untuk format float
    with pd.option_context('display.float_format', '{:,.4f}'.format):
         display(recs_df[['anime_id', 'name', 'genre', 'type', 'rating', 'predicted_rating']].reset_index(drop=True))
    # --- AKHIR MODIFIKASI ---


    # Visualisasi Predicted Rating
    plt.figure(figsize=(12, 8))
    sns.barplot(data=recs_df, x='predicted_rating', y='name', palette='coolwarm')
    plt.title(f'Top {top_n} Rekomendasi (Predicted Rating)')
    plt.xlabel('Predicted Rating')
    plt.ylabel('Anime')
    plt.tight_layout()
    plt.show()

"""**SVD**

Percobaan 1
"""

random.seed(49)
all_ids = df_rating_cf['user_id'].tolist()
rand_id = random.choice(all_ids)

recommend_cf_verbose(user_id=rand_id,
                     pred_df=pred_df_svd,
                     df_anime=df_anime,
                     user_matrix=user_matrix_train,
                     top_n=5)

"""Insight: Dari hasil rekomendasi untuk user dengan ID 23427, anime yang direkomendasikan menunjukkan dominasi genre komedi, drama, dan romansa, dengan judul-judul seperti "Clannad" dan "Yowamushi Pedal: Grande Road" yang memiliki kesamaan tematik. Predicted rating untuk rekomendasi teratas seperti "Fate/Zero 2nd Season" dengan nilai 0.6063 cukup tinggi, dan menunjukkan potensi daya tarik yang besar bagi pengguna. Namun, judul seperti "Neon Genesis Evangelion" dengan nilai 0.4697 menunjukkan bahwa meskipun rating aktualnya tinggi, daya tariknya mungkin tidak sekuat yang diharapkan.

Percobaan 2
"""

random.seed(46)
all_ids = df_rating_cf['user_id'].tolist()
rand_id = random.choice(all_ids)

recommend_cf_verbose(user_id=rand_id,
                     pred_df=pred_df_svd,
                     df_anime=df_anime,
                     user_matrix=user_matrix_train,
                     top_n=5)

"""Insight: Dari hasil rekomendasi untuk anime "Kiseijuu: Sei no Kakuritsu" menunjukkan bahwa semua rekomendasi teratas berputar di sekitar genre aksi, drama, dan psikologi, dengan judul seperti "Guilty Crown" dan "Kaichou wa Maid-sama!" yang memiliki kesamaan tinggi. Predicted rating yang bervariasi, dengan "Kiseijuu: Sei no Kakuritsu" memiliki nilai 0.6803, menunjukkan potensi daya tarik yang besar bagi pengguna. Namun, judul seperti "Samurai Champloo" dengan nilai 0.4739 menunjukkan bahwa meskipun rating aktualnya tinggi, daya tariknya mungkin tidak sekuat yang diharapkan.

### **Kelebihan & Kekurangan Model Development dengan Collaborative Filtering**

Bagian ini mengembangkan model rekomendasi menggunakan pendekatan Collaborative Filtering (CF), khususnya metode Model-Based SVD. Pendekatan ini memiliki kelebihan dan kekurangan tersendiri dibandingkan dengan pendekatan Content-Based Filtering:
Kelebihan Collaborative Filtering (SVD):
1. Model berbasis SVD dapat menemukan hubungan antar item atau pengguna berdasarkan pola rating yang kompleks. Ini bisa merekomendasikan item yang secara konten mungkin tidak mirip dengan apa yang disukai pengguna sebelumnya, tetapi disukai oleh pengguna lain dengan selera serupa.
2. Model ini hanya memerlukan data interaksi (rating pengguna terhadap item). Anda tidak perlu memiliki deskripsi detail, genre, atau fitur lain dari item itu sendiri untuk membuat rekomendasi. Ini sangat berguna ketika fitur item sulit didapatkan atau diukur.
3. Dibandingkan Content-Based Filtering yang cenderung merekomendasikan item yang sangat mirip, CF dapat merekomendasikan item yang berbeda namun relevan, berdasarkan apa yang disukai oleh "tetangga" pengguna yang memiliki selera serupa.
4. Rekomendasi didasarkan pada "kebijaksanaan orang banyak". Jika banyak pengguna dengan selera serupa menyukai suatu item, model cenderung merekomendasikan item tersebut, bahkan jika fitur itemnya sendiri tidak sepenuhnya menjelaskan preferensi tersebut.

Kekurangan Collaborative Filtering (SVD):
1. Masalah Cold Start Pengguna dan Item:
  *   Jika pengguna baru belum memberikan rating yang cukup, model CF kesulitan memahami seleranya dan memberikan rekomendasi yang relevan. Matriks pengguna-item akan memiliki banyak nilai kosong untuk pengguna tersebut.
  *   Item yang baru ditambahkan ke database dan belum memiliki rating yang cukup dari banyak pengguna juga sulit direkomendasikan karena tidak ada data interaksi yang cukup untuk SVD menemukan faktor latennya.
2. Jika matriks rating sangat jarang (sparse) karena sebagian besar pengguna hanya merating sedikit item, performa model berbasis dekomposisi matriks seperti SVD bisa menurun. Sulit menemukan pola yang kuat dari data yang sangat sedikit.
3. Meskipun SVD menemukan faktor laten, seringkali sulit untuk memberikan makna intuitif atau menjelaskan mengapa model merekomendasikan item tertentu berdasarkan faktor-faktor abstrak tersebut.
4. Melatih model SVD pada matriks pengguna-item yang sangat besar bisa membutuhkan sumber daya komputasi yang signifikan dan waktu yang lama. Namun, teknik SVD yang dioptimalkan (seperti yang digunakan di sini, svds) dirancang untuk menangani matriks sparse yang besar.

Secara ringkas, Collaborative Filtering dengan SVD sangat baik dalam menemukan pola tersembunyi dan memberikan rekomendasi yang mengejutkan, tetapi rentan terhadap masalah data yang jarang (terutama untuk pengguna/item baru) dan hasilnya bisa kurang mudah dijelaskan dibandingkan dengan Content-Based Filtering.

### **Evaluasi Menggunakan RMSE**

Bagian ini bertujuan untuk mengevaluasi kinerja model Collaborative Filtering (CF) berbasis Singular Value Decomposition (SVD) yang telah dilatih sebelumnya. Metrik evaluasi yang digunakan adalah RMSE (Root Mean Squared Error).
"""

actual_ratings = user_matrix_train[user_matrix_train > 0].stack().reset_index()
actual_ratings.columns = ['user_id', 'anime_id', 'actual_rating']
predicted_ratings = []
for index, row in actual_ratings.iterrows():
    user = row['user_id']
    anime = row['anime_id']

    if user in pred_df_svd.index and anime in pred_df_svd.columns:
        pred = pred_df_svd.loc[user, anime]
        predicted_ratings.append(pred)
    else:
        predicted_ratings.append(np.nan)

actual_ratings['predicted_rating'] = predicted_ratings

# Hapus baris dengan NaN jika ada
actual_ratings = actual_ratings.dropna()

"""Bagian evaluasi ini fokus pada pengukuran kinerja model rekomendasi berbasis Collaborative Filtering (CF) yang dilatih menggunakan teknik Singular Value Decomposition (SVD). Untuk mengukur seberapa baik model ini dalam memprediksi rating pengguna, digunakan metrik Root Mean Squared Error (RMSE). Pertama-tama mempersiapkan data dengan mengekstrak semua rating eksplisit (nilai lebih besar dari 0) dari matriks pelatihan dan menyusunnya dalam format tabel yang mudah dikelola, di mana setiap baris mewakili satu interaksi rating pengguna-anime beserta nilai rating aktualnya. Kemudian, secara iteratif mencari rating yang diprediksi oleh model SVD untuk setiap interaksi pengguna-anime yang memiliki rating aktual, mencocokkannya berdasarkan ID pengguna dan anime.

Hasil prediksi ini disimpan dalam list, dan jika prediksi tidak tersedia untuk pasangan tertentu, ditandai dengan nilai kosong (NaN). List prediksi ini kemudian ditambahkan sebagai kolom baru pada tabel rating aktual. Langkah terakhir dalam persiapan data adalah menghapus baris-baris yang memiliki nilai kosong (akibat prediksi yang tidak tersedia), memastikan bahwa hanya data dengan pasangan rating aktual dan prediksi yang lengkap yang akan digunakan dalam perhitungan. Setelah data disiapkan, baris kode utama evaluasi menghitung RMSE. Ini dilakukan dengan mengambil akar kuadrat dari Mean Squared Error (MSE) antara kolom rating aktual dan kolom rating prediksi yang baru saja dibuat. Nilai MSE dihitung dengan merata-ratakan kuadrat perbedaan antara setiap rating aktual dan rating prediksinya.
"""

# Hitung RMSE
rmse_cf = np.sqrt(mean_squared_error(actual_ratings['actual_rating'], actual_ratings['predicted_rating']))

print(f"RMSE for Collaborative Filtering (SVD Model): {rmse_cf:.4f}")

"""Hasil RMSE yang diperoleh kemudian dicetak ke layar, dibulatkan hingga empat angka desimal, memberikan nilai tunggal yang merangkum rata-rata "kesalahan" prediksi model dalam skala rating yang sama (0-10). Nilai RMSE yang lebih rendah menunjukkan bahwa prediksi model rata-rata lebih dekat dengan rating sebenarnya, mengindikasikan performa prediksi yang lebih baik.

Output RMSE for Collaborative Filtering (SVD Model): 7.2628 mengindikasikan bahwa model Collaborative Filtering berbasis SVD yang dilatih, dengan konfigurasi data dan parameter saat ini, menghasilkan prediksi rating yang memiliki tingkat kesalahan rata-rata cukup besar. Ini menyarankan bahwa model ini mungkin tidak cukup akurat untuk memprediksi rating eksplisit pengguna secara andal pada data yang dievaluasi. Untuk meningkatkan performa, mungkin perlu mempertimbangkan menggunakan dataset rating yang lebih besar, menyesuaikan parameter model SVD (seperti k), atau mencoba teknik CF lainnya.

## Requirements
"""

pip freeze > requirements.txt